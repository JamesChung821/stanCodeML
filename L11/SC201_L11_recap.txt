[ SC201 - L11 - #重點回顧 ]
-
各位同學哈囉！
今天課程如果都能吸收，之後的圖像辨識、語音辨識就只是微調 NN 在 Feature Extractor 的部分了！
非常開心看到大家都能吸收這麼難的數學＆程式概念
-
L10 的重點回顧有六點：
-
1.) NN 的所有參數（W1, B1, W2, B2, ...）在隨機初始化要以零為中心 (zero-centered) 會好 train 好多
-
2.) Forward Prop 我們將每一層乘上 W 加上 B 稱之為 K ; 將 K 通過 ReLU 稱之為 A ; 而最後一層 Output Layer 是最特別的！我們不用 ReLU 而是使用 sigmoid 因為正確答案不是 0 就是 1
-
3.) Backward Prop 要小心微分的 dimension!!!! 還有在 np.sum 的時候也要特別注意 axis 為何 🤔 
-
4.) 再搭造 Deep NN 時一定要找到每一層之間的關聯性、縮短程式碼的行數！這可以讓同學們接軌到所有網站上的 AI codes (幾乎所有 AI 領域的人都是這樣寫的 😉)
-
5.) 圖像辨識目前我們學到的是使用「每一張圖片的每一個 pixel 的每一個 RGB 數值」來當作 features (總共 64x64x3 個)! 
    • 匯入圖片可以使用 PIL 裡面的 img = Image.open('檔名.jpg') 
    • 將所有圖片檔名列出找到可以使用 os.listdir()
    • 將每一張圖片變成矩陣可以使用 np.array(img)
-
6.) 雖然這個模型只有 ~55% 左右的準確率，但 pixels + NN 這個概念卻是之後 96% 圖像辨識 AI 演算法的基礎！萬丈高樓平地起，我們下週就會介紹更棒的演算法，大家敬請期待 😋